# ğŸ¦ AML Graph System

A production-ready Anti-Money Laundering (AML) system that combines graph analytics with machine learning for real-time transaction risk scoring.

## ğŸ—ï¸ Architecture

| Layer   | Purpose           | Technology |
| ------- | ----------------- | ---------- |
| Neo4j   | Graph brain       | Neo4j + GDS |
| ML      | Risk engine       | XGBoost + scikit-learn |
| FastAPI | Real-time scoring | FastAPI |

## ğŸ“¦ Project Structure

```
aml-graph-system/
â”‚
â”œâ”€â”€ app/                      â† FastAPI service (production layer)
â”‚   â”œâ”€â”€ main.py              â† API endpoints
â”‚   â”œâ”€â”€ model_loader.py      â† Load trained model
â”‚   â”œâ”€â”€ feature_builder.py   â† Extract graph features
â”‚   â””â”€â”€ schemas.py           â† Request/response models
â”‚
â”œâ”€â”€ ml/                       â† ML pipeline (training layer)
â”‚   â”œâ”€â”€ export_features.py   â† Pull features from Neo4j
â”‚   â”œâ”€â”€ build_dataset.py     â† Merge transaction + graph data
â”‚   â”œâ”€â”€ train_model.py       â† Train XGBoost model
â”‚   â””â”€â”€ utils.py             â† Helper functions
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  â† Original CSV files
â”‚   â””â”€â”€ processed/            â† ML-ready datasets
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ aml_model.pkl        â† Trained model
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Prepare Data

Place your transaction CSV in `data/raw/transactions.csv`

Ensure Neo4j is running with graph features computed (PageRank, Betweenness, Degree, Community)

### 3. Train the Model

```bash
# Step 1: Export graph features from Neo4j
python ml/export_features.py

# Step 2: Build training dataset
python ml/build_dataset.py

# Step 3: Train XGBoost model
python ml/train_model.py
```

### 4. Start the API

```bash
uvicorn app.main:app --reload
```

API will be available at: `http://127.0.0.1:8000`

Interactive docs at: `http://127.0.0.1:8000/docs`

## ğŸ¯ API Usage

### Score a Transaction

**POST** `/score`

```json
{
  "amount": 5000.0,
  "nameOrig": "C1234567890",
  "nameDest": "C9876543210"
}
```

**Response:**

```json
{
  "risk_score": 0.87
}
```

## ğŸ§  Features Used

- **Transaction amount**
- **Source account PageRank** (centrality in network)
- **Destination account PageRank**
- **Account degree** (number of connections)
- **Account betweenness** (bridge position in network)

## ğŸ”§ Configuration

Update Neo4j credentials in:
- `ml/export_features.py`
- `app/feature_builder.py`

```python
driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "your_password"))
```

## ğŸ“Š Model Details

- **Algorithm:** XGBoost Classifier
- **Class balancing:** `scale_pos_weight=10` (handles fraud imbalance)
- **Features:** 5 (amount + 4 graph metrics)
- **Output:** Fraud probability (0-1)

## ğŸ¯ Next Steps

- **Add SHAP explainability** for model interpretability
- **Batch scoring** for historical analysis
- **Dockerization** for easy deployment
- **Model monitoring** and retraining pipeline
- **A/B testing** framework

## ğŸ“ Notes

This is a production-style PoC that demonstrates:
- Separation of training and serving layers
- Graph feature engineering
- Real-time API scoring
- Scalable architecture

Ready to scale to production with proper infrastructure!
